{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a58591-424e-43c8-a31a-5471728edc2a",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "The aim of this project is to categorize text descriptions into 4 distinct categories. The dataset required for this project can be accessed at https://www.kaggle.com/datasets/saurabhshahane/ecommerce-text-classification?select=ecommerceDataset.csv. Multiple text classification algorithms are employed in this project to demonstrate their varying levels of accuracy.\n",
    "- Bag of words with SVM\n",
    "- Bag of words and Lemmatization with SVM\n",
    "- N-grams with SVM\n",
    "- TF-IDF with SVM\n",
    "\n",
    "TF-IDF produces best results with 98% accuracy. Bag of words yields 96%. N-grams does not improve previous result, but takes much longer to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c1344-abf1-480e-9ac6-a540fd00ecea",
   "metadata": {},
   "source": [
    "# Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbee9376-eaae-4c7a-976e-1d98cf767e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general modules\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5940007-6007-4d5b-8db0-31f9fb6fcc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file\n",
    "df = pd.read_csv('ecommerceDataset.csv', header =None)\n",
    "df.rename(columns = {0 : 'Label', 1: 'Text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "110f406e-edfd-4d60-8325-84d12ea99299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Household                 19313\n",
       "Books                     11820\n",
       "Electronics               10621\n",
       "Clothing & Accessories     8671\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine number of unique labels\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f66f43-5f98-4ae0-9457-ac18242ac548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Household\n",
      "Text: Paper Plane Design Framed Wall Hanging Motivational Office Decor Art Prints (8.7 X 8.7 inch) - Set of 4 Painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it. This is an special series of paintings which makes your wall very beautiful and gives a royal touch. This painting is ready to hang, you would be proud to possess this unique painting that is a niche apart. We use only the most modern and efficient printing technology on our prints, with only the and inks and precision epson, roland and hp printers. This innovative hd printing technique results in durable and spectacular looking prints of the highest that last a lifetime. We print solely with top-notch 100% inks, to achieve brilliant and true colours. Due to their high level of uv resistance, our prints retain their beautiful colours for many years. Add colour and style to your living space with this digitally printed painting. Some are for pleasure and some for eternal bliss.so bring home this elegant print that is lushed with rich colors that makes it nothing but sheer elegance to be to your friends and family.it would be treasured forever by whoever your lucky recipient is. Liven up your place with these intriguing paintings that are high definition hd graphic digital prints for home, office or any room.\n"
     ]
    }
   ],
   "source": [
    "# visualize the first example\n",
    "print(f\"Label: {df['Label'][0]}\")\n",
    "print(f\"Text: {df['Text'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84e6008-6abc-4bbb-9b19-6984ac26b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null values in the text is 1\n",
      "Number of Null values in the text is 0\n"
     ]
    }
   ],
   "source": [
    "# detect Null values\n",
    "print(f\"Number of Null values in the text is {df['Text'].isnull().sum()}\")\n",
    "\n",
    "# drop Null values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# detect Null values\n",
    "print(f\"Number of Null values in the text is {df['Text'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d8b90c-34ba-409c-8559-5fc5f39e9369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50424,)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# label encode y. y contains 4 categories.\n",
    "LE = LabelEncoder()\n",
    "y = LE.fit_transform(df['Label'])\n",
    "print(y.shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa128384-63ee-4de1-9564-d2fbc7ce9268",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bag of words with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a59fc9-70de-4b4b-a889-7f80357c9f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50424, 78571)\n",
      "78571\n",
      "CPU times: total: 1.95 s\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', max_df=0.5)\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "# dimensions of X matrix - bag of words\n",
    "print(X.shape)\n",
    "\n",
    "# dimensions of feature names\n",
    "names = vectorizer.get_feature_names_out()\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a3cdad-5903-4a2d-88e0-1f7212c636e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40339, 78571)\n",
      "(40339,)\n",
      "(10085, 78571)\n",
      "(10085,)\n",
      "CPU times: total: 4min 1s\n",
      "Wall time: 6min 59s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# divide into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# apply SVM to text classification\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12c05b7-6850-4a1b-a4d1-675b3361a2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      2327\n",
      "           1       0.97      0.97      0.97      1702\n",
      "           2       0.98      0.93      0.95      2119\n",
      "           3       0.96      0.96      0.96      3937\n",
      "\n",
      "    accuracy                           0.96     10085\n",
      "   macro avg       0.96      0.96      0.96     10085\n",
      "weighted avg       0.96      0.96      0.96     10085\n",
      "\n",
      "Accuracy: 0.9565691621219633\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a20e7-d42e-4a45-b0c3-3ea3caae7fb0",
   "metadata": {},
   "source": [
    "# Bag of words + Lemmatization with SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2ae70b-ce62-4581-8f92-1a5019f30533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to apply lemmatization and remove stop words\n",
    "def lemmatize_stop_punct(text):\n",
    "    \n",
    "    string = \"\"\n",
    "    for token in nlp(text):\n",
    "        if not token.is_stop and token.pos_ == 'NOUN':\n",
    "            string = string + token.lemma_ + \" \"\n",
    "\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4cb8e0f-f7e7-460e-90c2-11c5fef348c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 37s\n",
      "Wall time: 13min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        x inch painting frame uv print effect attract ...\n",
       "1        inch inch uv painting frame uv print effect at...\n",
       "2        uv painting cm cm cm color | painting action s...\n",
       "3        inch inch uv | cm painting action skill paint ...\n",
       "4        x size size picture text rest life size plaque...\n",
       "                               ...                        \n",
       "50420    mobile life gadget picture music video lot spa...\n",
       "50421                                                     \n",
       "50422    w4 power phone pocket mb ram phone operating s...\n",
       "50423    sm phone pocket price feature need trust glitc...\n",
       "50424                                                 win \n",
       "Name: Text_lemma, Length: 50424, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# apply function\n",
    "filename = 'lemmatized_data.csv'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    df['Text_lemma'] = df['Text'].apply(lemmatize_stop_punct)\n",
    "    df['Text_lemma'].to_csv('lemmatized_data.csv', index=False)\n",
    "else:\n",
    "    df['Text_lemma'] = pd.read_csv('lemmatized_data.csv')\n",
    "\n",
    "# show table\n",
    "df['Text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7782153e-facb-4110-9432-d43daef71484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.80      2327\n",
      "           1       0.96      0.78      0.86      1702\n",
      "           2       0.96      0.79      0.87      2119\n",
      "           3       0.91      0.86      0.88      3937\n",
      "\n",
      "    accuracy                           0.85     10085\n",
      "   macro avg       0.88      0.84      0.85     10085\n",
      "weighted avg       0.88      0.85      0.86     10085\n",
      "\n",
      "Accuracy: 0.8525532969757065\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(lowercase=True, stop_words='english', max_df=0.5)),  # Step 1: Vectorize the text data\n",
    "    ('clf', svm.SVC())  # Step 2: Train a SVM classifier on the data\n",
    "])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df['Text_lemma']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline on the test data and produce classification report\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952c883-7f7e-43f0-9682-b926939229d8",
   "metadata": {},
   "source": [
    "# N-grams with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a63acf9e-3256-4349-9c36-f2c00a8f6cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      2327\n",
      "           1       0.97      0.97      0.97      1702\n",
      "           2       0.98      0.93      0.96      2119\n",
      "           3       0.96      0.96      0.96      3937\n",
      "\n",
      "    accuracy                           0.96     10085\n",
      "   macro avg       0.96      0.96      0.96     10085\n",
      "weighted avg       0.96      0.96      0.96     10085\n",
      "\n",
      "Accuracy: 0.9578582052553297\n",
      "CPU times: total: 8min 6s\n",
      "Wall time: 17min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2), lowercase=True, stop_words='english', max_df=0.5)),  # Step 1: Vectorize the text data\n",
    "    ('clf', svm.SVC())  # Step 2: Train a SVM classifier on the data\n",
    "])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df['Text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline on the test data and produce classification report\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255d01f-baea-4c1b-a54c-818ca0dc5831",
   "metadata": {},
   "source": [
    "# TF-IDF with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34ceccb1-7389-47e0-b8d0-c94d9b76735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      2327\n",
      "           1       0.98      0.98      0.98      1702\n",
      "           2       0.98      0.96      0.97      2119\n",
      "           3       0.97      0.99      0.98      3937\n",
      "\n",
      "    accuracy                           0.98     10085\n",
      "   macro avg       0.98      0.98      0.98     10085\n",
      "weighted avg       0.98      0.98      0.98     10085\n",
      "\n",
      "Accuracy: 0.9766980664353\n",
      "CPU times: total: 3min 13s\n",
      "Wall time: 11min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=10000, lowercase=True)),  # Step 1: Vectorize the text data\n",
    "    ('clf', svm.SVC())  # Step 2: Train a SVM classifier on the data\n",
    "])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df['Text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline on the test data and produce classification report\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
